{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Face Classification Project - Group 8"
      ],
      "metadata": {
        "id": "n__ACZHll0cj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmn9gCJMme4R",
        "outputId": "cd7d5ddd-8a55-43c9-c8f0-e1a71fc012d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Face Detection\n",
        "\"\"\"\n",
        "Mounting the Google drive\n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to install deepface if not already installed in ur notebook\n",
        "pip install deepface"
      ],
      "metadata": {
        "id": "pNvfy43dIjGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_7vnq3pZG6qp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Imports"
      ],
      "metadata": {
        "id": "9Gj8D6mXGmdc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Py0Pb9Ir-SYG",
        "outputId": "a8c50d78-5315-4bd1-8af4-6b6089442009",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24-03-18 01:17:50 - Directory /root/.deepface created\n",
            "24-03-18 01:17:50 - Directory /root/.deepface/weights created\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "from skimage import exposure\n",
        "\n",
        "from deepface import DeepFace\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# modules for augmentation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "\n",
        "# modules for cleaning\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Augmentation"
      ],
      "metadata": {
        "id": "YtesNUAeGx5v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5MzmjYso-SYH"
      },
      "outputs": [],
      "source": [
        "root_dir = \"/content/drive/MyDrive/Colab Notebooks/COEN240_TA/data\"\n",
        "data_dir = root_dir + \"/train\"                # Directory with original images -- Need to change this according to your folder path\n",
        "label_file = data_dir + \"/file_mapping.txt\"  # File with label mappings\n",
        "output_dir = root_dir + \"/Augmented_images\"  # Directory to save augmented images -- Keep as is\n",
        "\n",
        "# Load label mappings from a space-separated text file\n",
        "label_mapping = {}\n",
        "with open(label_file, 'r') as file:\n",
        "    for line in file:\n",
        "        filename, label = line.strip().split(' ')\n",
        "        label_mapping[filename] = label\n",
        "\n",
        "# Initialize the ImageDataGenerator with desired augmentations\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=5,\n",
        "    rescale=1./255,\n",
        "    zoom_range=0.2,\n",
        "    brightness_range = (0.5,1.0),\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Function to save augmented images in label-specific folders\n",
        "def save_augmented_images(directory, output_directory, label_mapping, num_augmented_images=5):\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename in label_mapping:  # Check if the file has a mapping\n",
        "            label = label_mapping[filename]  # Get the label for the current file\n",
        "            label_dir = os.path.join(output_directory, label)  # Define label-specific directory path\n",
        "\n",
        "            if not os.path.exists(label_dir):\n",
        "                os.makedirs(label_dir)  # Create the directory if it doesn't exist\n",
        "\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            image = load_img(file_path)\n",
        "            image_array = img_to_array(image)\n",
        "            image_array = image_array.reshape((1,) + image_array.shape)\n",
        "\n",
        "            # Generate and save augmented images\n",
        "            i = 0\n",
        "            # Note: save_prefix is set to filename without extension to keep track of original image\n",
        "            save_prefix = os.path.splitext(filename)[0]\n",
        "            for batch in datagen.flow(image_array, batch_size=1, save_to_dir=label_dir, save_prefix=save_prefix, save_format='jpeg'):\n",
        "                i += 1\n",
        "                if i >= num_augmented_images:\n",
        "                    break  # Limit the number of augmented images generated per original image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the function to start the process\n",
        "save_augmented_images(data_dir, output_dir, label_mapping)"
      ],
      "metadata": {
        "id": "tLqM9HBJE5D9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DataCleaning"
      ],
      "metadata": {
        "id": "cEWjx0W0HDEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clean the data\n",
        "def clean_data(path):\n",
        "    shutil.rmtree(output_dir + \"/wufangyuan\")\n",
        "    folders = os.listdir(path)\n",
        "    for name in folders:\n",
        "        folder_path = os.path.join(path, name)\n",
        "        img_path = os.listdir(folder_path)\n",
        "        for img in img_path:\n",
        "            i_p = os.path.join(folder_path, img)\n",
        "            image = cv2.imread(i_p)\n",
        "            try:\n",
        "                DeepFace.extract_faces(image)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(i_p)\n",
        "                os.remove(i_p)\n",
        "                continue\n",
        "    return"
      ],
      "metadata": {
        "id": "dEq2AaZyE9bV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = output_dir\n",
        "print(\"Filtering Data\")\n",
        "clean_data(path)"
      ],
      "metadata": {
        "id": "TZF7ZdP0FAij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ebIi12bC-SYH"
      },
      "outputs": [],
      "source": [
        "# Face extractor\n",
        "\n",
        "def detect_faces(img: np.ndarray) -> np.ndarray:\n",
        "    try:\n",
        "        img = DeepFace.extract_faces(img)[0]['face']\n",
        "        return img\n",
        "    except ValueError:\n",
        "        return np.empty(shape = (0,))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load images from folders"
      ],
      "metadata": {
        "id": "JBEK2AfHHOoy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "w-02f5K4-SYH"
      },
      "outputs": [],
      "source": [
        "def load_images_from_folder(folder: str, file_map: map) -> list:\n",
        "    print(\"loading images from folder\")\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        if os.path.isfile(img_path):\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                images.append(img)\n",
        "                labels.append(file_map[filename])\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "def preprocess_images(images: list, face_detection: bool) -> list:\n",
        "    processed_images = []\n",
        "    print(\"pre - processing images\")\n",
        "    wrongCrop = 0\n",
        "\n",
        "    for i,img in enumerate(images):\n",
        "        backup = deepcopy(img)\n",
        "        # img = cv2.resize(img, (200, 200))\n",
        "\n",
        "        if face_detection == True:\n",
        "            img = detect_faces(img)\n",
        "            if img.size == 0:  # Check if the image is empty after face cropping\n",
        "                wrongCrop += 1\n",
        "                img = backup\n",
        "\n",
        "\n",
        "        img = cv2.resize(img, (128, 128))\n",
        "\n",
        "        processed_images.append(img)\n",
        "\n",
        "    # print(f\"wrong crop = {wrongCrop}\")\n",
        "    return processed_images\n",
        "\n",
        "def load_labels_from_file(mapping_file):\n",
        "    label_map = {}\n",
        "    with open(mapping_file, 'r') as file:\n",
        "        for line in file:\n",
        "            filename, label = line.strip().split(' ')\n",
        "            label_map[filename] = label\n",
        "    return label_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "D1pwa5Kg-SYI"
      },
      "outputs": [],
      "source": [
        "def load_keras_images(path):\n",
        "    folders = os.listdir(path)\n",
        "    labels = []\n",
        "    images = []\n",
        "    for name in folders:\n",
        "        folder_path = os.path.join(path,name)\n",
        "        img_path = os.listdir(folder_path)\n",
        "        # print(img_path)\n",
        "        for img in img_path:\n",
        "            image = cv2.imread(os.path.join(folder_path, img))\n",
        "            images.append(image)\n",
        "            labels.append(name)\n",
        "    return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "C-M2mh-r-SYI"
      },
      "outputs": [],
      "source": [
        "def load_images(path:str, Face_detect = False, keras = False) -> np.array:\n",
        "    # Load images from a folder\n",
        "    images = []\n",
        "    if not keras:\n",
        "\n",
        "        # Load labels from the mapping file\n",
        "        mapping_file_path = os.path.join(path,\"file_mapping.txt\")\n",
        "        label_map = load_labels_from_file(mapping_file_path)\n",
        "        images, labels = load_images_from_folder(path, label_map)\n",
        "\n",
        "\n",
        "    else:\n",
        "        images, labels = load_keras_images(path)\n",
        "\n",
        "    # Preprocess the images\n",
        "    preprocessed_images = preprocess_images(images, Face_detect)\n",
        "\n",
        "    # Convert preprocessed images to numpy array\n",
        "    data = np.array(preprocessed_images)\n",
        "\n",
        "    # Reshape data to flatten\n",
        "    data = data.reshape(len(data),-1)\n",
        "\n",
        "\n",
        "    return data, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "1JCG-L7cHUS_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "dT8cyh-a-SYI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd0c62c4-c3a8-40fb-9d13-6b6b8242c642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pre - processing images\n",
            "loading images from folder\n",
            "pre - processing images\n"
          ]
        }
      ],
      "source": [
        "Face_detect = True\n",
        "\n",
        "root_path = \"/content/drive/MyDrive/Colab Notebooks/COEN240_TA/data\"            # Adjust this according to your path\n",
        "\n",
        "train_path = root_path + \"/Augmented_images\"                                    # Keep as is, because this is wher the augmented images will be\n",
        "grade_path = root_path + \"/grade\"                                               # change as needed\n",
        "\n",
        "\n",
        "\n",
        "data, labels = load_images(train_path,Face_detect,keras=True)\n",
        "\n",
        "grade_data, grade_labels = load_images(grade_path,Face_detect)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML model"
      ],
      "metadata": {
        "id": "VfZplS28HcgI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "2XdI7eOZmqRv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "126a3f4d-ca9d-48a7-d82a-e58d198e5063"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8838709677419355\n"
          ]
        }
      ],
      "source": [
        "pip = Pipeline([\n",
        "      ('scaler', StandardScaler()),\n",
        "      ('pca', PCA(n_components = 390)),\n",
        "      ('lda', LinearDiscriminantAnalysis(n_components=31)),\n",
        "      ('svm', SVC(C = 5))\n",
        "     ])\n",
        "\n",
        "pip.fit(data, labels)\n",
        "y_pred = pip.predict(grade_data)\n",
        "score = pip.score(grade_data, grade_labels)\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating output csv"
      ],
      "metadata": {
        "id": "vzfW2UJ6O8XI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f_path = grade_path + \"/file_mapping.txt\"\n",
        "f_map = load_labels_from_file(f_path)\n",
        "folder = grade_path\n",
        "df = pd.DataFrame(columns=['filename', 'ground_truth'])\n",
        "for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        if os.path.isfile(img_path) and cv2.imread(img_path) is not None:\n",
        "          df = df.append({'filename': filename, 'ground_truth': f_map.get(filename, None)}, ignore_index=True)\n",
        "out = pd.DataFrame(y_pred, columns = ['predicted'])\n",
        "merged = pd.concat([df, out], axis = 1)"
      ],
      "metadata": {
        "id": "c1LQ9Apya15U"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged.to_csv(grade_path + \"/solution.csv\")"
      ],
      "metadata": {
        "id": "0sRzzCUqie7Y"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JJWsivZ8YSq-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "F4g7-lFGixN_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Assuming the CSV file has columns 'sample_id' and 'ground_truth'\n",
        "# made a slight change\n",
        "# predictions is not passed as im not creating a mapping of file name to predictions\n",
        "# So im reading this from the datafram, where it was already mapped and written\n",
        "# thus pass NONE to predictions\n",
        "\n",
        "def calculate_accuracy(ground_truths, predictions):\n",
        "    if len(ground_truths) != len(predictions):\n",
        "        raise ValueError(\"The number of predictions does not match the number of ground truths.\")\n",
        "    correct_predictions = 0\n",
        "    for sample_id, ground_truth in ground_truths.items():\n",
        "        if predictions.get(sample_id) == ground_truth:\n",
        "            correct_predictions += 1\n",
        "    return correct_predictions / len(ground_truths)\n",
        "\n",
        "def grade_predictions(predictions = None, grade_path=grade_path):\n",
        "    df = pd.read_csv(grade_path + \"/solution.csv\")\n",
        "    predictions = dict(zip(df['filename'], df['predicted']))\n",
        "    ground_truths = dict(zip(df['filename'], df['ground_truth']))\n",
        "    accuracy = calculate_accuracy(ground_truths, predictions)\n",
        "    return accuracy\n",
        "\n",
        "# Example usage\n",
        "# predictions = {'id1': 'A', 'id2': 'B', 'id3': 'C'}  # Your predictions\n",
        "# accuracy = grade_predictions(predictions)\n",
        "# print(f\"Prediction Accuracy: {accuracy * 100}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pass none to predictions because they are read in the grade_predictions function itself\n",
        "print(grade_predictions(None, grade_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMu53xoTYewC",
        "outputId": "a1e5286c-e9a5-403e-c58f-aed6e4c41f86"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8838709677419355\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}